% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/information_theory.R
\name{fdiv_kernel_list}
\alias{fdiv_kernel_list}
\title{Generate list of f-divergence kernel functions}
\usage{
fdiv_kernel_list()
}
\value{
Named list of functions, each accepting a numeric vector \code{t}
  and returning the kernel value. Elements:
  \describe{
    \item{KL}{Kullback-Leibler: \eqn{f(t) = t \log(t)}}
    \item{exp}{Exponential divergence: \eqn{f(t) = t (\log t)^2}}
    \item{chi_sq}{Pearson chi-squared: \eqn{f(t) = (t-1)^2}}
    \item{Hellinger}{Squared Hellinger: \eqn{f(t) = (\sqrt{t}-1)^2}}
    \item{Jeffreys}{Jeffreys (symmetric KL): \eqn{f(t) = (t-1) \log(t)}}
    \item{total_var}{Total variation: \eqn{f(t) = |t-1|/2}}
  }
}
\description{
Returns a named list of f-divergence kernel functions, each taking a
density ratio \eqn{t = p(x)/q(x)} as input. Useful for visualizing and
comparing how different divergence measures behave.
}
\details{
An f-divergence between distributions \eqn{P} and \eqn{Q} is defined as:
\deqn{D_f(P \| Q) = \int q(x) f\left(\frac{p(x)}{q(x)}\right) dx}
where \eqn{f} is a convex function with \eqn{f(1) = 0}.

The kernel functions returned here are the \eqn{f(\cdot)} functions for
various common divergences. Evaluating them at density ratios
\eqn{t = p(x)/q(x)} shows how each divergence penalizes deviations from
\eqn{t = 1} (where \eqn{P = Q}).
}
\section{Kernel properties at key points}{

\itemize{
  \item At \eqn{t = 1}: all kernels equal 0 (no divergence when \eqn{P = Q})
  \item At \eqn{t = 0}: KL and exponential are defined as 0 by continuity;
        chi-squared and Hellinger equal 1; Jeffreys is undefined
  \item As \eqn{t \to \infty}: all kernels grow, but at different rates
}
}

\examples{
fn_lst <- fdiv_kernel_list()

# Evaluate KL kernel at various density ratios
t_vals <- c(0.5, 1, 2)
fn_lst$KL(t_vals)

# Compare kernel values at t = 2 (P twice as likely as Q)
sapply(fn_lst, function(f) f(2))

}
\references{
Liese, F., and Vajda, I. (2006). On Divergences and Informations in
Statistics and Information Theory.
IEEE Transactions on Information Theory, 52(10), 4394-4412.
}
\seealso{
\code{\link{fdiv_kernel_table}} to evaluate all kernels on a vector of
density ratios,
\code{\link{kl_divergence}} for computing KL divergence between distributions
}
