---
name: "Chapter 14: Frequency Domain Methods"
description: >
  Content knowledge and tutoring guidance for the EDA Companion when
  the student is working on Chapter 14 materials.
applyTo: "**/ch14*"
---

<!-- Last updated: 2026-02-25 -->

<!-- Source of truth: eda4ml-positron/ch-instructions/ch14.instructions.md -->

# Chapter 14: Frequency Domain Methods

## Chapter Scope and Position

Chapter 14 develops the frequency-domain perspective that Chapter 12
introduced conceptually and Chapter 13 left implicit in time-domain
models. Where Chapter 13 asked "how does the past predict the future?"
this chapter asks "what periodic components structure this process?"
The emphasis shifts from forecasting to understanding.

**The intellectual arc:** Chapters 12-13 established that time series
have memory and showed how to exploit that memory for forecasting.
Chapter 14 completes the picture by developing the spectral view:
the spectrum decomposes variance by frequency, revealing cycles and
periodic structure that may be obscured in time-domain diagnostics.
The chapter closes the trilogy by consolidating the dual perspectives.

**Pedagogical approach:** The chapter moves from theory to estimation
to application. It derives ARMA spectra (connecting Chapter 13's model
parameters to frequency features), then confronts the periodogram's
inconsistency problem (a surprising result that motivates smoothing),
then applies the tools to sunspots and city temperatures. Coherence
analysis extends the framework to pairs of series. The chapter closes
by explicitly comparing and unifying the two perspectives.

**Assumed background:** Chapter 12 (ACF, spectrum concept, Fourier
transform pair relationship). Chapter 13 (AR, MA, ARMA models). The
eigenfunction argument from Chapter 12 provides the mathematical
motivation.

**Where it leads:** This is the final time series chapter. Students
pursuing signal processing, climate science, or neuroscience will
encounter more advanced spectral methods. The dual-perspective theme
connects to the broader book arc of understanding and decision support.

---

## Learning Objectives

The student should be able to:

1. Interpret the spectrum as a decomposition of variance by
   frequency. (LO 1)
2. Compute and interpret the periodogram of a time series. (LO 2)
3. Explain the relationship between the spectrum and the
   autocorrelation function. (LO 3)
4. Apply spectral smoothing to obtain consistent spectral
   estimates. (LO 4)
5. Identify dominant frequencies in a time series using spectral
   analysis. (LO 5)
6. Compute coherence between two series and interpret what it reveals
   about shared periodicity. (LO 6)
7. Describe the spectral density function of an AR(1) or MA(1)
   model. (LO 7)

---

## Concept Inventory

| Concept                                                                        | Key LOs |
| ------------------------------------------------------------------------------ | ------- |
| Spectrum as variance decomposition: integrating f(lambda) gives total variance | LO 1    |
| Spectral peak = dominant periodic component; flat = white noise                | LO 1, 5 |
| Low-frequency dominance = persistence/trend; high-frequency = alternation      | LO 1    |
| Periodogram: sample spectrum estimate via DFT                                  | LO 2    |
| Fourier frequencies, FFT computation                                           | LO 2    |
| Periodogram inconsistency: variance does not shrink with sample size           | LO 2, 4 |
| Chi-squared distribution of periodogram ordinates                              | LO 2    |
| Spectrum and ACF as Fourier transform pairs                                    | LO 3    |
| Spectral smoothing: averaging periodogram ordinates                            | LO 4    |
| Bandwidth trade-off: resolution vs. stability                                  | LO 4    |
| Modified Daniell kernel, `spans` argument                                      | LO 4    |
| Reading spectral peaks: frequency to period conversion                         | LO 5    |
| Harmonics: non-sinusoidal waveforms produce multiple peaks                     | LO 5    |
| Cross-spectrum and coherence                                                   | LO 6    |
| Coherence as squared correlation at each frequency                             | LO 6    |
| AR(1) spectrum: phi > 0 peaks at zero, phi < 0 peaks at pi                     | LO 7    |
| MA(1) spectrum: opposite pattern from AR(1)                                    | LO 7    |
| AR(2) spectral peak from complex roots                                         | LO 7    |
| General ARMA spectrum formula                                                  | LO 7    |

---

## Exercise Map

### Book Exercises (Chapter 14)

| Exercise | Topic                                                        | Key LOs |
| -------- | ------------------------------------------------------------ | ------- |
| 1        | White noise spectrum: raw vs. smoothed periodogram           | LO 2, 4 |
| 2        | Periodogram distribution: chi-squared verification           | LO 2    |
| 3        | AR spectrum identification using `astsa::arma.spec()`        | LO 7    |
| 4        | SOI spectrum: dominant peaks, frequency-to-period conversion | LO 5    |
| 5        | Sunspot cycle: peak identification, breadth, harmonics       | LO 5    |
| 6        | Global temperature spectrum: trend signature                 | LO 1, 5 |
| 7        | Bandwidth selection: narrow vs. medium vs. wide              | LO 4    |
| 8        | AR(2) spectrum: theoretical vs. sample comparison            | LO 7    |
| 9        | SOI-Recruitment coherence                                    | LO 6    |
| 10       | HNL-NYC temperature coherence                                | LO 6    |

### Workbook Exercises

| Exercise   | Tasks                                                            | Key LOs |
| ---------- | ---------------------------------------------------------------- | ------- |
| Exercise 1 | 1.1-1.2: Periodogram computation; 1.3: Smoothing                 | LO 2, 4 |
| Exercise 2 | 2.1: Smoothed estimation; 2.2: Dominant frequency identification | LO 4, 5 |
| Exercise 3 | 3.1-3.2: AR/MA spectral density functions                        | LO 7    |
| Exercise 4 | 4.1-4.3: Coherence computation and interpretation                | LO 6    |
| Problem 1  | Extended dominant frequency analysis                             | LO 5    |
| Problem 2  | Spectrum-ACF relationship                                        | LO 1    |

---

## Common Misconceptions

**1. "The periodogram tells you the spectrum."**

The periodogram is asymptotically unbiased but *inconsistent*: its
variance does not shrink with sample size. Each ordinate is
approximately chi-squared with 2 degrees of freedom, regardless of
how many observations you have. The periodogram is a noisy picture
that must be smoothed before interpretation.

*Probe:* "I have a million data points. Will the periodogram be
smooth? What mathematical result tells you the answer?"

**2. "Smoothing the spectrum just makes it look prettier."**

Smoothing trades frequency resolution for statistical stability.
A smoothed estimate averages over nearby frequencies, reducing
variance by a factor proportional to bandwidth. But wider bandwidth
blurs peaks that are close together. This is a genuine bias-variance
trade-off, not cosmetic.

*Probe:* "If two spectral peaks are close together, how might your
choice of bandwidth determine whether you see one peak or two?"

**3. "High coherence means one series causes the other."**

Coherence measures linear association at each frequency, like
correlation. High coherence at the annual frequency between Honolulu
and NYC temperatures reflects a shared cause (Earth's orbital
mechanics), not one city causing the other's weather. Coherence
identifies shared periodic structure without implying direction.

*Probe:* "HNL and NYC temperatures have coherence near 1 at the
annual frequency and near 0 at daily frequencies. What does each
tell you about the underlying mechanisms?"

**4. "The spectrum is only useful for data with obvious cycles."**

The spectrum characterizes *any* stationary process. A flat spectrum
means white noise; low-frequency dominance means persistence; a broad
hump indicates quasi-periodic behavior. Even when there are no sharp
peaks, the spectral shape conveys information about the dependence
structure.

*Probe:* "The global temperature spectrum has no peaks, just
low-frequency dominance. What does this spectral shape tell you about
the nature of the series?"

**5. "Frequency-domain and time-domain methods are competing
approaches; you should pick one."**

They are complementary, not competing. The sunspot data illustrate
this: an AR(2) model captures the quasi-periodic behavior for
forecasting, while the spectrum reveals the ~11-year cycle and shows
that its period varies (the peak is broad, not sharp). Each view
illuminates what the other obscures.

*Probe:* "For the sunspot data, what does the spectrum tell you that
the fitted AR(2) model does not?"

**6. "You need a lot of data for spectral analysis to be useful."**

Even modest sample sizes can reveal dominant periodicities if the
signal is strong. The sunspot spectrum is clear with a few hundred
years of data. The issue is not sample size per se but the number
of cycles observed: to detect a 10-year cycle, you need at least
a few decades of data. The periodogram's inconsistency means that
more data does not automatically give you a smoother estimate; for
that you need explicit smoothing.

*Probe:* "If you have 20 years of monthly data, what is the longest
period you could reliably detect? Why?"

---

## Scaffolding Strategies

**When the student is confused by the periodogram inconsistency:**
This is genuinely surprising. Most statistical estimates improve with
more data. The periodogram does not, because each Fourier frequency
gets essentially one "observation." Draw the analogy: imagine
estimating 100 different means, each from a single observation. More
data gives you more means to estimate, not more observations per mean.
Smoothing is like averaging neighboring estimates.

**When the student struggles to convert frequency to period:**
The formula is P = 2*pi/lambda (or P = 1/f if frequency is in cycles
per unit time). Practice with the sunspot data: a peak at ~0.007
cycles per month means a period of ~1/0.007 = 143 months, or about
12 years. Work through several conversions until the student is
comfortable reading peaks.

**When the student cannot interpret the coherence plot:**
Focus on the HNL-NYC temperature example, which has a clear story.
At the annual frequency, coherence is nearly 1: both cities share the
same seasonal cause. At daily frequencies, coherence is nearly 0:
Honolulu's weather today tells you nothing about NYC's. Ask: "What
physical mechanism explains each pattern?"

**When the student is confused by ARMA spectra:**
Start with the AR(1) formula. When phi > 0, the denominator is
smallest at lambda = 0, so the spectrum peaks at low frequencies:
the process is persistent. When phi < 0, the denominator is smallest
at lambda = pi: the process alternates. Ask: "Does this match what
you know about positive vs. negative autocorrelation from Chapter 12?"

**When the student struggles with the degrees-of-freedom argument:**
The smoothed spectrum estimate has approximately 2m degrees of
freedom, where m is the number of periodogram ordinates averaged.
The raw periodogram has only 2 degrees of freedom per ordinate.
Think of it as: each periodogram ordinate is like one observation
of a chi-squared random variable. Averaging m of them gives you m
times less variance. The R output reports these degrees of freedom
alongside the confidence band.

**When the student confuses spectral peaks with deterministic cycles:**
A sharp spectral peak indicates a strong periodic component, but
the process may still be stochastic. The sunspot cycle has a broad
peak because its period varies from 9 to 14 years. A purely
deterministic sinusoid would produce a line spectrum (zero width).
Ask: "What does the width of the spectral peak tell you about
whether the cycle is regular or irregular?"

---

## Key Connections

**Backward to earlier chapters:**

- Fourier transform pair (Ch 12): The spectrum and ACF contain the
  same information. This chapter develops the estimation side.
- Eigenfunction argument (Ch 12): Complex exponentials as natural
  coordinates for time-invariant systems motivates the spectral
  decomposition.
- AR, MA, ARMA models (Ch 13): Their theoretical spectra connect
  time-domain parameters to frequency-domain features.
- Eigendecomposition (Ch 8): Spectral analysis decomposes variance
  into frequency components, paralleling PCA's decomposition into
  principal components.

**Forward connections:**

- This is the final time series chapter. The dual-perspective
  consolidation connects back to the book's overarching theme of
  understanding and decision support as complementary aims.

**If the student asks about topics not covered in this chapter:**

- Wavelets: Acknowledge as tools for non-stationary signals where
  frequency content changes over time. Beyond scope but a natural
  extension.
- Multitaper estimation: A more sophisticated approach to spectrum
  estimation that avoids some periodogram problems. Mention as
  advanced practice.
- Dynamic spectral analysis: Time-varying spectra for non-stationary
  processes. Conceptually important but beyond scope.

---

## Terminology

| Term                    | Definition                                                               |
| ----------------------- | ------------------------------------------------------------------------ |
| Spectrum                | Fourier transform of autocovariance; variance decomposition by frequency |
| Periodogram             | Sample estimate of the spectrum based on the DFT                         |
| Fourier frequency       | Frequencies at which the DFT is computed: 2*pi*j/T                       |
| Inconsistency           | Periodogram variance does not shrink with sample size                    |
| Bandwidth               | Width of the smoothing window; controls resolution-stability trade-off   |
| Modified Daniell kernel | Smoothing kernel for spectrum estimation (R's `spans` argument)          |
| Coherence               | Squared correlation between two series at each frequency                 |
| Cross-spectrum          | Fourier transform of the cross-covariance function                       |
| Harmonic                | Spectral peak at a multiple of a fundamental frequency                   |
| Spectral leakage        | Spurious spread of spectral power from one frequency to neighbors        |

---

## Companion Guidance

This chapter completes the time series trilogy. By its end, the
student should have both perspectives firmly integrated: the time-domain
view for forecasting and the frequency-domain view for understanding
periodic structure. The consolidation section ("The Dual Perspectives")
is the intellectual payoff.

The periodogram inconsistency result is a pedagogical opportunity. Students often assume more data always yield more reliable estimates. Here it does not, and the reason is illuminating: increased sample size gives finer frequency resolution of the periodogram rather than reduced variance. Let the student sit with this surprise before
presenting the smoothing solution.

Coherence analysis is often the most directly useful frequency-domain
tool for applied work. Students working with multiple related time
series (e.g., economic indicators, environmental measurements) will
find coherence immediately applicable.

Students with mathematics or physics backgrounds may want to pursue
the spectral representation theorem, the connection between spectral
analysis and Hilbert spaces, or the relationship between the DFT and
circulant matrices. These are rich mathematical veins that the chapter
opens but does not fully develop.
